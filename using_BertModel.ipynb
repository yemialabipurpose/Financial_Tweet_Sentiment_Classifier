{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtUdMDm_AVsC",
        "outputId": "8c8ae875-8f36-478b-8b6a-42eae5cf0267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (3.8.1)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (1.3.0)\n",
            "Requirement already satisfied: transformers in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (4.31.0)\n",
            "Requirement already satisfied: joblib in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk) (1.3.1)\n",
            "Requirement already satisfied: click in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk) (8.1.6)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-learn) (1.11.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-learn) (1.24.3)\n",
            "Requirement already satisfied: requests in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tqdm->nltk) (0.4.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yemia\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->transformers) (3.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 23.2 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\yemia\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "pip install nltk scikit-learn transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Install torch in terminal copy code below. after installation restart notebook.\n",
        "#pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\yemia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\yemia\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Downloading model.safetensors: 100%|██████████| 440M/440M [00:13<00:00, 33.7MB/s] \n",
            "C:\\Users\\yemia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\yemia\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.41      0.43       285\n",
            "           1       0.55      0.43      0.49       391\n",
            "           2       0.79      0.87      0.83      1233\n",
            "\n",
            "    accuracy                           0.71      1909\n",
            "   macro avg       0.60      0.57      0.58      1909\n",
            "weighted avg       0.69      0.71      0.70      1909\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import  accuracy_score, classification_report\n",
        "# Install the stopwords resource\n",
        "nltk.download('stopwords')\n",
        "# Download the punkt tokenizer\n",
        "#nltk.download('punkt')\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('sent_train.csv')\n",
        "\n",
        "# Data cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\$[A-Za-z]+', '', text)  # Remove stock symbols\n",
        "    text = re.sub(r'\\W+', ' ', text.lower())  # Remove non-word characters and convert to lowercase\n",
        "    return text.strip()\n",
        "\n",
        "data['cleaned_text'] = data['text'].apply(clean_text)\n",
        "\n",
        "# Remove stop words and perform stemming\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "data['processed_text'] = data['cleaned_text'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split() if word not in stop_words]))\n",
        "\n",
        "# Now, 'processed_text' column contains the preprocessed text data\n",
        "\n",
        "# Initialize BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize and encode the text data using BERT tokenizer\n",
        "inputs = tokenizer(data['processed_text'].tolist(), padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# Extract BERT embeddings\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    bert_embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
        "\n",
        "# Prepare target variable\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(bert_embeddings, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the SVM classifier\n",
        "svm_classifier = SVC(kernel='linear', C=1.0)\n",
        "\n",
        "# Train the classifier\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluating Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>$ALLY - Ally Financial pulls outlook https://t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>$DELL $HPE - Dell, HPE targets trimmed on comp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>$PRTY - Moody's turns negative on Party City h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>$SAN: Deutsche Bank cuts to Hold</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>$SITC: Compass Point cuts to Sell</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  $ALLY - Ally Financial pulls outlook https://t...      0\n",
              "1  $DELL $HPE - Dell, HPE targets trimmed on comp...      0\n",
              "2  $PRTY - Moody's turns negative on Party City h...      0\n",
              "3                   $SAN: Deutsche Bank cuts to Hold      0\n",
              "4                  $SITC: Compass Point cuts to Sell      0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the data\n",
        "val_data = pd.read_csv('sent_valid.csv')\n",
        "val_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>$ALLY - Ally Financial pulls outlook https://t...</td>\n",
              "      <td>0</td>\n",
              "      <td>ally financial pulls outlook</td>\n",
              "      <td>alli financi pull outlook</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>$DELL $HPE - Dell, HPE targets trimmed on comp...</td>\n",
              "      <td>0</td>\n",
              "      <td>dell hpe targets trimmed on compute headwinds</td>\n",
              "      <td>dell hpe target trim comput headwind</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>$PRTY - Moody's turns negative on Party City h...</td>\n",
              "      <td>0</td>\n",
              "      <td>moody s turns negative on party city</td>\n",
              "      <td>moodi turn neg parti citi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>$SAN: Deutsche Bank cuts to Hold</td>\n",
              "      <td>0</td>\n",
              "      <td>deutsche bank cuts to hold</td>\n",
              "      <td>deutsch bank cut hold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>$SITC: Compass Point cuts to Sell</td>\n",
              "      <td>0</td>\n",
              "      <td>compass point cuts to sell</td>\n",
              "      <td>compass point cut sell</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label  \\\n",
              "0  $ALLY - Ally Financial pulls outlook https://t...      0   \n",
              "1  $DELL $HPE - Dell, HPE targets trimmed on comp...      0   \n",
              "2  $PRTY - Moody's turns negative on Party City h...      0   \n",
              "3                   $SAN: Deutsche Bank cuts to Hold      0   \n",
              "4                  $SITC: Compass Point cuts to Sell      0   \n",
              "\n",
              "                                    cleaned_text  \\\n",
              "0                   ally financial pulls outlook   \n",
              "1  dell hpe targets trimmed on compute headwinds   \n",
              "2           moody s turns negative on party city   \n",
              "3                     deutsche bank cuts to hold   \n",
              "4                     compass point cuts to sell   \n",
              "\n",
              "                         processed_text  \n",
              "0             alli financi pull outlook  \n",
              "1  dell hpe target trim comput headwind  \n",
              "2             moodi turn neg parti citi  \n",
              "3                 deutsch bank cut hold  \n",
              "4                compass point cut sell  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_data['cleaned_text'] = val_data['text'].apply(clean_text)\n",
        "val_data['processed_text'] = val_data['cleaned_text'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split() if word not in stop_words]))\n",
        "\n",
        "# Tokenize the preprocessed text (sentences)\n",
        "#val_data['tokenized_text'] = val_data['processed_text'].apply(word_tokenize)\n",
        "\n",
        "val_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.41      0.44       347\n",
            "           1       0.57      0.49      0.53       475\n",
            "           2       0.80      0.86      0.83      1566\n",
            "\n",
            "    accuracy                           0.72      2388\n",
            "   macro avg       0.61      0.59      0.60      2388\n",
            "weighted avg       0.71      0.72      0.71      2388\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Tokenize and encode the text data using BERT tokenizer\n",
        "val_inputs = tokenizer(val_data['processed_text'].tolist(), padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# Extract BERT embeddings\n",
        "with torch.no_grad():\n",
        "    outputs = model(**val_inputs)\n",
        "    val_bert_embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
        "\n",
        "# Prepare target variable\n",
        "val_y = val_data['label']\n",
        "\n",
        "\n",
        "# Model prediction on val data\n",
        "val_y_pred = svm_classifier.predict(val_bert_embeddings)\n",
        "# Model evaluation\n",
        "val_accuracy = accuracy_score(val_y, val_y_pred)\n",
        "print(f\"Accuracy: {val_accuracy:.2f}\")\n",
        "print(classification_report(val_y, val_y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
